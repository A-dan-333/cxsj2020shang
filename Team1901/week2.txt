1.TextRank算法  整理者：李浚铭

Textrank是一种用来做关键词提取的算法，也可以用于提取短语和自动摘要。 

TextRank算法提取关键词
TextRank是由PageRank改进而来，其公式有颇多相似之处，这里给出TextRank的公式：
WS(Vi)=(1−d)+d∗∑j∈In(Vi)  wji/∑Vk∈Out(Vj)wjkWS(Vj)

TextRank用于关键词提取的算法如下：
　　 (1）把给定的文本T按照完整句子进行分割;
　　（2）对于每个句子，进行分词和词性标注处理，并过滤掉停用词，只保留指定词性的单词，如名词、动词、形容词;
　　（3）构建候选关键词图G = (V,E)，其中V为节点集，由（2）生成的候选关键词组成，然后采用共现关系（co-occurrence）构造任两点之间的边，两个节点之间存在边仅当它们对应的词汇在长度为K的窗口中共现，K表示窗口大小，即最多共现K个单词。
　　（4）根据上面公式，迭代传播各节点的权重，直至收敛。
　　（5）对节点权重进行倒序排序，从而得到最重要的T个单词，作为候选关键词。
　　（6）由（5）得到最重要的T个单词，在原始文本中进行标记，若形成相邻词组，则组合成多词关键词。例如，文本中有句子“Matlab code for plotting ambiguity function”，如果“Matlab”和“code”均属于候选关键词，则组合成“Matlab code”加入关键词序列。

小结：讲真的这段看得很迷，那个窗口长度我就没找到是什么意思，姑且先讲一下我的理解吧，先将一个文本进行拆分成基本词，然后在拆分后的词中去掉一些不重要的词（比如连接词，语气词，数量词，标点符号等等）再根据删除这些词后得到的文章进行关键词连接（即每个词与后面切割出来的五个词进行关联，大概）并对连接词进行计数，选取频率最高的几个关联词作为文章的关键词，并且如果某些关键词系属与同一个分类，就可以将他们进行连接，形成一个词

2.LDA算法  整理者：熊峰

LDA模型将一份文档分为三个层次:文档(document)—主题(topic)—词(word).
相互的关系为多对多,既多个文档,对应多个主题,对应多个词.将文档到词从小到大,从高到低分为d,t,w级,再将文档的集合设为D级.则,
D=d1+d2+d3+d4+…..dn     -----①
d=a1*t1+a2*t2+……+an*tn    -----②
t=b1*w1+b2*w2+……+bn*wn    -----③
(n∈N,①②③中的n并不相等,但an,bn分别求和均等于1 )
由此可得每一个高级个体都是多个低级概率分布的集合.
新的文档将根据已有的概率模型进行分类,同时反过来影响概率模型中的概率分布的平均值(修正分类标准),初始标准不必一定正确,随着d样本的增多,概率模型将不断趋向于真实值.
总而言之,每一个新的d样本都将根据已有的标准被分类,同时反过来影响分类标准.


3.LSA算法  整理者：王俊伟
是对一个文档的潜在语义进行分析的算法。主要是在解决两类问题，一类是一词多义，一类是一义多词。会使用SVD来对单词-文档矩阵进行分解。SVD可以看作是从单词-文档矩阵中发现不相关的索引变量(因子)，将原来的数据映射到语义空间内。在单词-文档矩阵中不相似的两个文档，可能在语义空间内比较相似。
S VD（奇异值分解），是对矩阵进行分解的一种方法，一个t*d维的矩阵(单词-文档矩阵)X，可以分解为T*S*DT，其中T为t*m维矩阵，T中的每一列称为左奇异向量，S为m*m维对角矩阵，每个值称为奇异值，D为d*m维矩阵,D中的每一列称为右奇异向量。在对单词文档矩阵X做SVD分解之后，我们只保存S中最大的K个奇异值，以及T和D中对应的K个奇异向量，K个奇异值构成新的对角矩阵S ’，K个左奇异向量和右奇异向量构成新的矩阵T ’和D ’：X’=T’*S’*D’   T形成了一个新的t*d矩阵。


